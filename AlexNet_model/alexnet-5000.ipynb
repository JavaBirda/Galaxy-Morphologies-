{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Dropout\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D,  GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from keras.datasets import mnist\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Softmax,Activation,Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0=list(os.listdir('dataset0/0'))\n",
    "l_1=list(os.listdir('dataset0/1'))\n",
    "l_2=list(os.listdir('dataset0/2'))\n",
    "l_3=list(os.listdir('dataset0/3'))\n",
    "l_4=list(os.listdir('dataset0/4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l_0)+len(l_1)+len(l_2)+len(l_3)+len(l_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "def list_images(basePath, contains=None):\n",
    "    # 返回有效的图片路径数据集\n",
    "    return list_files(basePath, validExts=image_types, contains=contains)\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # 遍历图片数据目录，生成每张图片的路径\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # 循环遍历当前目录中的文件名\n",
    "        for filename in filenames:\n",
    "            # if the contains string is not none and the filename does not contain\n",
    "            # the supplied string, then ignore the file\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "             # 通过确定.的位置，从而确定当前文件的文件扩展名\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "            \n",
    "            # 检查文件是否为图像，是否应进行处理\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                # 构造图像路径\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# 读取数据和标签\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------开始读取数据------\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(list_images('dataset0')))\n",
    "random.seed(0)\n",
    "random.shuffle(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    data.append(image)\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    if len(data)==5000:\n",
    "        break\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "trainX /= 255\n",
    "testX /= 255\n",
    "trainY=np.array(trainY)\n",
    "print(type(trainY))\n",
    "testY=np.array(testY)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " trainY=to_categorical(trainY,num_classes=5)\n",
    "testY=to_categorical(testY,num_classes=5)\n",
    "print(trainX.shape) \n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Dropout\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D,  GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from keras.datasets import mnist\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Softmax,Activation,Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALEXNET(X,Y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(64,64,3),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "model=ALEXNET(trainX,trainY)\n",
    " \n",
    "model.compile(\"adam\",\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "def scheduler(epoch):\n",
    "    # 每隔10个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "hist=model.fit(trainX, trainY, batch_size=32, epochs=20, \n",
    "               callbacks=[reduce_lr],\n",
    "#                validation_split=0.1\n",
    "#                early_stopping,reduce_lr\n",
    "               validation_data=(testX,testY)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costrain,acctr=model.evaluate(trainX, trainY, batch_size=64)\n",
    "cost,acc = model.evaluate(testX, testY, batch_size=64)\n",
    "print (\"训练集准确度 = \" , acctr)\n",
    "print (\"测试集准确度 = \" ,acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history.get(\"accuracy\")[0:],\"green\")\n",
    "plt.plot(hist.history.get(\"val_accuracy\")[0:],color='#054E9F')\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history.get(\"loss\")[1:],\"green\")\n",
    "plt.plot(hist.history.get(\"val_loss\")[1:],color='#054E9F')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds_keras = roc_curve(testY[:,0], predY[:,0])\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(\"AUC : \",auc_val)\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f})'.format(auc_val))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
