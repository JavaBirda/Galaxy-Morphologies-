{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    " \n",
    "from matplotlib.pyplot import imshow\n",
    " \n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import *\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.utils import plot_model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Softmax,Activation,Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0=list(os.listdir('dataset0/0'))\n",
    "l_1=list(os.listdir('dataset0/1'))\n",
    "l_2=list(os.listdir('dataset0/2'))\n",
    "l_3=list(os.listdir('dataset0/3'))\n",
    "l_4=list(os.listdir('dataset0/4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l_0),len(l_1),len(l_2),len(l_3),len(l_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "def list_images(basePath, contains=None):\n",
    "    # 返回有效的图片路径数据集\n",
    "    return list_files(basePath, validExts=image_types, contains=contains)\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # 遍历图片数据目录，生成每张图片的路径\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # 循环遍历当前目录中的文件名\n",
    "        for filename in filenames:\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------开始读取数据------\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(list_images('dataset0')))\n",
    "random.seed(0)\n",
    "random.shuffle(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    data.append(image)\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    if len(data)==1000:\n",
    "        break\n",
    "print(len(data))\n",
    "print(\"------读取文件结束------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "trainX /= 255\n",
    "testX /= 255\n",
    "trainY=np.array(trainY)\n",
    "\n",
    "testY=np.array(testY)\n",
    "print(type(trainX))\n",
    "print(type(trainY))\n",
    "print(type(testX))\n",
    "print(type(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY=to_categorical(trainY,num_classes=5)\n",
    "testY=to_categorical(testY,num_classes=5)\n",
    "print(trainX.shape) \n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_13(X,Y):\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(64,64,3),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128,(3,2),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "model=VGG_13(trainX,trainY)\n",
    " \n",
    "model.compile(\"adam\",\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "def scheduler(epoch):\n",
    "    # 每隔10个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " hist=model.fit(trainX, trainY, batch_size=32, epochs=50, \n",
    "                callbacks=[reduce_lr],\n",
    "    #                reduce_lr,,early_stopping\n",
    "                validation_data=(testX,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costrain,acctr=model.evaluate(trainX, trainY, batch_size=64)\n",
    "cost,acc = model.evaluate(testX, testY, batch_size=64)\n",
    "print (\"训练集准确 = \" , acctr)\n",
    "print (\"测试集准确度 = \" ,acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history.get(\"accuracy\")[0:],\"green\")\n",
    "plt.plot(hist.history.get(\"val_accuracy\")[0:],color='#054E9F')\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history.get(\"loss\")[0:],\"green\")\n",
    "plt.plot(hist.history.get(\"val_loss\")[0:],color='#054E9F')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(testX)\n",
    "fpr, tpr, thresholds_keras = roc_curve(testY[:,0], predY[:,0])\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(\"AUC : \",auc_val)\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f})'.format(auc_val))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
