{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import random\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Softmax,Activation,Dense,BatchNormalization\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist,cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "\n",
    "num_classes = 5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0=list(os.listdir('dataset0/0'))\n",
    "l_1=list(os.listdir('dataset0/1'))\n",
    "l_2=list(os.listdir('dataset0/2'))\n",
    "l_3=list(os.listdir('dataset0/3'))\n",
    "l_4=list(os.listdir('dataset0/4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l_0))\n",
    "print(len(l_1))\n",
    "print(len(l_2))\n",
    "print(len(l_3))\n",
    "print(len(l_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "def list_images(basePath, contains=None):\n",
    "    # 返回有效的图片路径数据集\n",
    "    return list_files(basePath, validExts=image_types, contains=contains)\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # 遍历图片数据目录，生成每张图片的路径\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # 循环遍历当前目录中的文件名\n",
    "        for filename in filenames:\n",
    "            # if the contains string is not none and the filename does not contain\n",
    "            # the supplied string, then ignore the file\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "             # 通过确定.的位置，从而确定当前文件的文件扩展名\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "            \n",
    "            # 检查文件是否为图像，是否应进行处理\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                # 构造图像路径\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# 读取数据和标签\n",
    "print(\"------开始读取数据------\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(list_images('dataset0')))\n",
    "random.seed(0)\n",
    "random.shuffle(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    if len(data)==15000:\n",
    "        break\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "trainX /= 255\n",
    "testX /= 255\n",
    "trainY=np.array(trainY)\n",
    "print(type(trainY))\n",
    "testY=np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainY = [ int(x) for x in trainY ]\n",
    "testY = [int(x) for x in testY ]\n",
    "trainY=np.array(trainY)\n",
    "testY=np.array(testY)\n",
    "print(trainX.shape) \n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\", \n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    # Third component of main path (≈2 lines)\n",
    "\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X\n",
    " \n",
    "\n",
    "def MyNet(input_shape = (64, 64, 3), classes = 5):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), name=\"conv\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64,256], stage=2, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"c\")\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    # The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"d\")\n",
    "    \n",
    "    # Stage 4 (≈6 lines)\n",
    "    # The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"d\")\n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "    X = AveragePooling2D(pool_size=(1, 1), padding=\"same\")(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1000)(X)\n",
    "    X = Dense(128)(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "    model.summary()\n",
    "    return model\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred): # Tensor上的操作\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def plot_train_history(history, train_metrics, val_metrics):\n",
    "    plt.plot(history.history.get(train_metrics))\n",
    "    plt.plot(history.history.get(val_metrics))\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[0,0,0,0,0]\n",
    "for i in range(len(trainY)):\n",
    "   lis[int(trainY[i])]+=1\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(trainY== i)[0] for i in range(5)]\n",
    "print(len(digit_indices))\n",
    "print(type(digit_indices))\n",
    "print(digit_indices[0].shape)\n",
    "print(digit_indices[1].shape)\n",
    "print(digit_indices[2].shape)\n",
    "print(digit_indices[3].shape)\n",
    "print(digit_indices[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "#     n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        n= len(digit_indices[d])-1\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            if(i>len(digit_indices[dn])-1):\n",
    "                labels += [1]\n",
    "                continue\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pairs, tr_y = create_pairs(trainX, digit_indices)\n",
    "print(tr_pairs.shape)\n",
    "print(type(tr_pairs))\n",
    "print(len(tr_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_indices = [np.where( testY == i)[0] for i in range(5)]\n",
    "te_pairs, te_y = create_pairs(testX, digit_indices)\n",
    "print(te_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = trainX.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# def scheduler(epoch):\n",
    "#     # 每隔10个epoch，学习率减小为原来的1/10\n",
    "#     if epoch % 10 == 0 and epoch != 0:\n",
    "#         lr = K.get_value(model.optimizer.lr)\n",
    "#         K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "#         print(\"lr changed to {}\".format(lr * 0.1))\n",
    "#     return K.get_value(model.optimizer.lr)\n",
    "def scheduler(epoch):\n",
    " \n",
    "    if epoch == 10 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    if epoch == 20 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 10)\n",
    "        print(\"lr changed to {}\".format(lr * 10))\n",
    "    if epoch == 30 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    if epoch == 40 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 10)\n",
    "        print(\"lr changed to {}\".format(lr * 10))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "for i in range(10):\n",
    "    print(\"++++++++++++\",i,\"+++++++++++++++++\")\n",
    "    base_network = MyNet(input_shape)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "\n",
    "    # because we re-use the same instance `base_network`,\n",
    "    # the weights of the network\n",
    "    # will be shared across the two branches\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    distance = Lambda(euclidean_distance,\n",
    "                      output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "    model = Model([input_a, input_b], distance)\n",
    " \n",
    "    opt =RMSprop(lr=0.001)\n",
    "    model.compile(loss=contrastive_loss, optimizer=opt, metrics=[accuracy])\n",
    "    history=model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "              batch_size=32,\n",
    "              epochs=40,verbose=1,\n",
    "              callbacks=[reduce_lr],\n",
    "    #                   ,early_stopping\n",
    "              validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "yr_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, yr_pred)\n",
    "ye_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, ye_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history.get(\"accuracy\")[0:],\"green\")\n",
    "plt.plot(history.history.get(\"val_accuracy\")[0:],color='#054E9F')\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history.get(\"loss\")[2:],\"green\")\n",
    "plt.plot(history.history.get(\"val_loss\")[2:],color='#054E9F')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.grid(alpha=1,linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(history.history.get(\"loss\")[0:])\n",
    "plt.plot(history.history.get(\"val_loss\")[0:])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    " \n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(history.history.get(\"accuracy\")[0:])\n",
    "plt.plot(history.history.get(\"val_accuracy\")[0:])\n",
    "plt.ylabel(\"acc\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    " \n",
    "fpr, tpr, thresholds_keras = roc_curve(tr_y[:,0], y_pred[:,0])\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(\"AUC : \",auc_val)\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f})'.format(auc_val))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for i in range(len(yr_pred)):\n",
    "    if(tr_y[i]==1 and yr_pred[i]==1 or tr_y[i]==0 and yr_pred[i]==0 ):\n",
    "        n+=1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "41677/42779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(yr_pred)):\n",
    "    if(yr_pred[i]>0.5):\n",
    "        yr_pred[i]=0\n",
    "    else:\n",
    "        yr_pred[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr, tpr, thresholds_keras = roc_curve(tr_y, yr_pred)\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(\"AUC : \",auc_val)\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f})'.format(auc_val))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
